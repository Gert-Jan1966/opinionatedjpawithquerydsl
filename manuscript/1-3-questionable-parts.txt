# Questionable parts {#ch-questionable-parts}

The JPA, as any ORM, is not without its drawbacks. Firstly, it is complex, much deeper than
developers realize when they approach it. Secondly, it is not a perfect abstraction. The more you
want to play it that way (as a perfect abstraction) the worse it probably gets in marginal cases.
And the margin is not very thin. You may solve 80% cases easily, but there are still 20% of hard
cases where you go around your ORM, write native SQL, etc. If you try to avoid it you'll probably
suffer more than if you accepted it.

You can't just stay on the JPA level, even for cases where ORM works well for you. There are
these details you should know about a provider you use. For instance, let's say you have an entity
with auto-generated identifier based on IDENTITY (or AUTO_INCREMENT) column. You call `persist`
on it and later you want to use its ID somewhere. And it doesn't work, because you're using
EclipseLink and you didn't call `flush` to actually execute that INSERT. Without it the provider
cannot know what value for ID it should use. Maybe your usage of ID value was not the right
*ORM way*, maybe you should have use the whole entity somewhere, but the point is that if you do
the same with Hibernate, it would work. You simply cannot assume that the ID is set.[^demoid]

[^demoid]: You can see this demonstrated in `examples/basic` if you run: `mvn test-compile
exec:java -Dexec.mainClass="tests.GeneratedIdSettingDemo"`

## Lazy on basic and *to-one* fields {#lazy-problems}

TODO

## Generated updates

* unit-of-work works only with whole entities, it does not emit partial updates

## Big unit of work

* unit-of-work "caching" and tracking a lot of data that are to be viewed (can be fixed with
readonly transactions, nice example of being explicit)

## Unit of work vs queries

TODO

## Second-level cache vs queries {#cache-vs-queries}

While persistence context (`EntityManager` or session) is sometimes considered a cache too, it
is merely a part of the unit-of-work pattern. The real cache sits underneath and is shared on the
level of the `EntityManagerFactory` -- or even between more of them across various JVMs in case
of distributed caches. This is called the *second-level cache*.[^slc] It is used to enhance performance,
typically by avoiding round-trips to the database. But caching has consequences.

[^slc]: Second-level cache is most popular term, used also in [[JPspec](#bib-jpspec)]. It appears
in [[PJPA2](#bib-projpa2)] too, but *in-memory cache* is used more often there.

[[JPspec](#bib-jpspec)] doesn't say much about caching. It says how to configure it -- starting
with `shared-cache-mode` in your `persistence.xml`. But I'd probably study caching documentation
of a particular provider. In general, if you don't care at all, you don't even know whether and
how you use the cache.

Without choosing `shared-cache-mode` it is up to the JPA provider and its defaults. This may render
any use of `@Cacheable` annotations useless. Currently, Hibernate typically doesn't cache by
default, while EclipseLink caches everything by default. Being oblivious to the cache (not related
to *cache-oblivious algorithms* at all) is rather dangerous, especially if your application is
not the only one running against the same database.

It is also important to know how the cache is structured. Typically there is an *entity cache*
that is easy to understand and helps with performance of `EntityManager.find` -- that is loading
by entity's `@Id` attribute. But this will not help you if you accidentally obfuscate what you
want with a query, that would otherwise return the same. The provider has no way to know what
entity (with what ID) will be loaded just looking at arbitrary where conditions. For this there
may be another cache, so called *query cache*. Bulk update and deletes using JPQL go around either
of these and the safest way how to avoid inconsistent data is to evict all entities of the modified
type from the caches.

Caching happens also directly on the database level. You still incur a network round-trip but it
does not necessarily load data from a disk (that would be really slow) and you don't have this
entity-query duality -- although we don't know how complex the database cache is. In any case, it
is used whether we use second-level cache or not.

Probably the most important question to answer is: Is your application the sole user of a particular
database? If yes, you may safely use the cache without much thinking (or defaults, which may be no
cache as well). This does not mean that is a good idea. If you start tuning it be prepared for
a walk that may be not that easy.

Still, entity cache returning you entities by ID really quickly, is a great idea in ORM world,
because it makes the problem of eager-loads of to-one relationships much smaller. It doesn't fix
it though as all those entities are part of your current persistence context whether you want them
or not. We already mentioned that units of work bigger than necessary are not for free.


## You can't escape SQL and relation model

TODO: Example: Paging with to-many fetching

Other problems:
* monitoring of SQL from JPA application is difficult (it's kinda "elsewhere") and the
interaction with the SQL itself has a lot of overhead as well (but this is complex topic anyway,
JDBC proxy driver is possibility, but how to connect to the business logic or place where it
happens?)
* updates of all columns when just one was changed (not inherent JPA problem, but happens)
* bugs cross-fire, different providers have different bugs, but all are show-stoppers for
a project

## And there is more

This list of potential surprises is far from complete and we will continue in similar tone at
the beginning of the following part.